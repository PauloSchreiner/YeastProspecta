import os

configfile: "config.yaml"


INPUT_DIR = config["directories"]["inputs"]
SUMMARY_DIR = config["directories"]["summary"]

TRIM_DIR = config["directories"]["trim_fastq"]
TRIM_REPORT_DIR = config["directories"]["trim_reports"]

CONSENSUS_DIR = config["directories"]["consensus_fasta"]
CONSENSUS_REPORT_DIR = config["directories"]["consensus_reports"]

BLAST_RAW_DIR = config["directories"]["blast_raw"]

TRIM_CUTOFF = config["parameters"]["trim_cutoff"]

files = glob_wildcards(os.path.join(INPUT_DIR, "{sample}_{primer}.ab1"))
samples, primers = files.sample, files.primer
unique_samples = list(set(samples)) # Necessary for the consensus rule

NCBI_API_KEY = os.environ.get("NCBI_KEY", "") # Checks for exported variable NCBI_KEY, defaults to blank


rule all:
    input:
        blast_raw = expand(os.path.join(BLAST_RAW_DIR, "{sample}_blast.xml"), sample = unique_samples),
        trim_summary = os.path.join(SUMMARY_DIR, "trim_metrics.tsv"),
        consensus_summary = os.path.join(SUMMARY_DIR, "consensus_summary.tsv")


rule trim:
    input:
        os.path.join(INPUT_DIR, "{sample}_{primer}.ab1")
    output:
        fastq = os.path.join(TRIM_DIR, "{sample}_{primer}_trimmed.fastq"),
        report = os.path.join(TRIM_REPORT_DIR, "{sample}_{primer}_trim_report.tsv")
    params:
        cutoff = TRIM_CUTOFF
    shell:
        """
        python3 workflow/scripts/trim.py -i {input} -o {output.fastq} --output_report {output.report} --trim_cutoff {params.cutoff}
        """


rule trim_aggregate:
    input:
        reports = expand(os.path.join(TRIM_REPORT_DIR, "{sample}_{primer}_trim_report.tsv"), 
               zip, sample=samples, primer=primers)
    output:
        summary = os.path.join(SUMMARY_DIR, "trim_metrics.tsv")
    run:
        import pandas as pd
        dfs = [pd.read_csv(f, sep='\t') for f in input.reports]
        final_df = pd.concat(dfs, ignore_index=True)
        final_df.to_csv(output.summary, sep='\t', index=False)


rule consensus:
    input:
        F_read = os.path.join(TRIM_DIR, "{sample}_F_trimmed.fastq"),
        R_read = os.path.join(TRIM_DIR, "{sample}_R_trimmed.fastq")
    output:
        fasta = os.path.join(CONSENSUS_DIR, "{sample}_consensus.fasta"),
        report = os.path.join(CONSENSUS_REPORT_DIR, "{sample}_consensus_report.txt")
    shell:
        """
        merger -asequence {input.F_read} \
        -bsequence {input.R_read} \
        -sreverse2 \
        -outseq {output.fasta} \
        -outfile {output.report}
        """


rule consensus_aggregate:
    input:
        reports = expand(os.path.join(CONSENSUS_REPORT_DIR, "{sample}_consensus_report.txt"),
                        sample = unique_samples)
    output:
        summary = os.path.join(SUMMARY_DIR, "consensus_summary.tsv")
    script:
        """
        scripts/consensus_aggregate.py
        """


rule blast:
    input:
        fasta = os.path.join(CONSENSUS_DIR, "{sample}_consensus.fasta")
    output:
        xml = os.path.join(BLAST_RAW_DIR, "{sample}_blast.xml")
    resources:
        ncbi_connection = 1
    shell:
        """
        export NCBI_API_KEY={NCBI_API_KEY}
        
        blastn \
        -db nt \
        -remote \
        -query {input.fasta} \
        -out {output.xml} \
        -outfmt 5
        """

"""
rule blast_aggregate:
    input: 
        xmls = expand(os.path.join(BLAST_RAW_DIR, "{sample}_blast.xml"), sample=unique_samples)

"""


