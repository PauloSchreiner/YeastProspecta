import os

configfile: "config.yaml"


INPUT_DIR = config["directories"]["inputs"]
SUMMARY_DIR = config["directories"]["summary"]

TRIM_DIR = config["directories"]["trim_fastq"]
TRIM_REPORT_DIR = config["directories"]["trim_reports"]

CONSENSUS_DIR = config["directories"]["consensus_fasta"]
CONSENSUS_REPORT_DIR = config["directories"]["consensus_reports"]


TRIM_CUTOFF = config["parameters"]["trim_cutoff"]

files = glob_wildcards(os.path.join(INPUT_DIR, "{sample}_{primer}.ab1"))
samples, primers = files.sample, files.primer

unique_samples = list(set(samples)) # Necessary for the consensus rule

rule all:
    input:
        expand(os.path.join(TRIM_DIR, "{sample}_{primer}_trimmed.fastq"), zip, sample=samples, primer=primers),
        os.path.join(SUMMARY_DIR, "trim_metrics.tsv"),
        expand(os.path.join(CONSENSUS_DIR, "{sample}_consensus.fasta"), sample=unique_samples)


rule trim:
    input:
        os.path.join(INPUT_DIR, "{sample}_{primer}.ab1")
    output:
        fastq = os.path.join(TRIM_DIR, "{sample}_{primer}_trimmed.fastq"),
        report = os.path.join(TRIM_REPORT_DIR, "{sample}_{primer}_trim_report.tsv")
    params:
        cutoff = TRIM_CUTOFF
    shell:
        "python3 scripts/trim.py -i {input} -o {output.fastq} --output_report {output.report} --trim_cutoff {params.cutoff}"


rule trim_aggregate:
    input:
        reports = expand(os.path.join(TRIM_REPORT_DIR, "{sample}_{primer}_trim_report.tsv"), 
               zip, sample=samples, primer=primers)
    output:
        summary = os.path.join(SUMMARY_DIR, "trim_metrics.tsv")
    run:
        import pandas as pd
        dfs = [pd.read_csv(f, sep='\t') for f in input.reports]
        final_df = pd.concat(dfs, ignore_index=True)
        final_df.to_csv(output.summary, sep='\t', index=False)


rule consensus:
    input:
        F_read = os.path.join(TRIM_DIR, "{sample}_F_trimmed.fastq"),
        R_read = os.path.join(TRIM_DIR, "{sample}_R_trimmed.fastq")
    output:
        fasta = os.path.join(CONSENSUS_DIR, "{sample}_consensus.fasta"),
        report = os.path.join(CONSENSUS_REPORT_DIR, "{sample}_consensus_report.txt")
    shell:
        "merger -asequence {input.F_read} \
        -bsequence {input.R_read} \
        -sreverse2 \
        -outseq {output.fasta} \
        -outfile {output.report}"


rule consensus_aggregate:
    pass
    # Goal: xtract data from all consensus reports and put it into a .tsv file. 
    # Maybe I could write a script that extract this data from a single file, and integrate it to snakemake using script: